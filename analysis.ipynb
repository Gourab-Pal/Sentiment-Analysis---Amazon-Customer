{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = \"https://www.datacamp.com/tutorial/text-analytics-beginners-nltk\">\n",
    "    Link for the tutorial\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important subfields of text analysis is sentiment analysis, which involves determining the emotional tone of the text. Sentiment analysis has numerous practical applications, from brand monitoring to customer feedback analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Natural Language Toolkit (NLTK) library is one of the most widely used libraries for natural language processing in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The NLTK library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit (NLTK) is a popular open-source library for natural language processing (NLP) in Python. It provides an easy-to-use interface for a wide range of tasks, including tokenization, stemming, lemmatization, parsing, and sentiment analysis.\n",
    "\n",
    "NLTK is widely used by researchers, developers, and data scientists worldwide to develop NLP applications and analyze text data.\n",
    "\n",
    "One of the major advantages of using NLTK is its extensive collection of corpora, which includes text data from various sources such as books, news articles, and social media platforms. These corpora provide a rich data source for training and testing NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a technique used to determine the emotional tone or sentiment expressed in a text. It involves analyzing the words and phrases used in the text to identify the underlying sentiment, whether it is positive, negative, or neutral.\n",
    "\n",
    "Sentiment analysis has a wide range of applications, including social media monitoring, customer feedback analysis, and market research.\n",
    "\n",
    "One of the main challenges in sentiment analysis is the inherent complexity of human language. Text data often contains sarcasm, irony, and other forms of figurative language that can be difficult to interpret using traditional methods.\n",
    "\n",
    "However, recent advances in natural language processing (NLP) and machine learning have made it possible to perform sentiment analysis on large volumes of text data with a high degree of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Methodologies for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to perform sentiment analysis on text data, with varying degrees of complexity and accuracy. The most common methods include a lexicon-based approach, a machine learning (ML) based approach, and a pre-trained transformer-based deep learning approach. Let’s look at each in more detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon-based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of analysis, such as the NLTK Vader sentiment analyzer, involves using a set of predefined rules and heuristics to determine the sentiment of a piece of text. These rules are typically based on lexical and syntactic features of the text, such as the presence of positive or negative words and phrases.\n",
    "\n",
    "While lexicon-based analysis can be relatively simple to implement and interpret, it may not be as accurate as ML-based or transformed-based approaches, especially when dealing with complex or ambiguous text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning (ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach involves training a model to identify the sentiment of a piece of text based on a set of labeled training data. These models can be trained using a wide range of ML algorithms, including decision trees, support vector machines (SVMs), and neural networks.\n",
    "\n",
    "ML-based approaches can be more accurate than rule-based analysis, especially when dealing with complex text data, but they require a larger amount of labeled training data and may be more computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained transformer-based deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deep learning-based approach, as seen with BERT and GPT-4, involve using pre-trained models trained on massive amounts of text data. These models use complex neural networks to encode the context and meaning of the text, allowing them to achieve state-of-the-art accuracy on a wide range of NLP tasks, including sentiment analysis. However, these models require significant computational resources and may not be practical for all use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumamry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexicon-based analysis is a straightforward approach to sentiment analysis, but it may not be as accurate as more complex methods.\n",
    "\n",
    "Machine learning-based approaches can be more accurate, but they require labeled training data and may be more computationally expensive.\n",
    "\n",
    "Pre-trained transformer-based deep learning approaches can achieve state-of-the-art accuracy but require significant computational resources and may not be practical for all use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing is a crucial step in performing sentiment analysis, as it helps to clean and normalize the text data, making it easier to analyze. The preprocessing step involves a series of techniques that help transform raw text data into a form you can use for analysis. Some common text preprocessing techniques include tokenization, stop word removal, stemming, and lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.oreilly.com/api/v2/epubs/9781492074076/files/assets/btap_0401.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is a text preprocessing step in sentiment analysis that involves breaking down the text into individual words or tokens. This is an essential step in analyzing text data as it helps to separate individual words from the raw text, making it easier to analyze and understand. Tokenization is typically performed using NLTK's built-in word_tokenize function, which can split the text into individual words and punctuation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop word removal is a crucial text preprocessing step in sentiment analysis that involves removing common and irrelevant words that are unlikely to convey much sentiment. Stop words are words that are very common in a language and do not carry much meaning, such as \"and,\" \"the,\" \"of,\" and \"it.\" These words can cause noise and skew the analysis if they are not removed.\n",
    "\n",
    "By removing stop words, the remaining words in the text are more likely to indicate the sentiment being expressed. This can help to improve the accuracy of the sentiment analysis. NLTK provides a built-in list of stop words for several languages, which can be used to filter out these words from the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are techniques used to reduce words to their root forms. Stemming involves removing the suffixes from words, such as \"ing\" or \"ed,\" to reduce them to their base form. For example, the word \"jumping\" would be stemmed to \"jump.\"\n",
    "\n",
    "Lemmatization, however, involves reducing words to their base form based on their part of speech. For example, the word \"jumped\" would be lemmatized to \"jump,\" but the word \"jumping\" would be lemmatized to \"jumping\" since it is a present participle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words model is a technique used in natural language processing (NLP) to represent text data as a set of numerical features. In this model, each document or piece of text is represented as a \"bag\" of words, with each word in the text represented by a separate feature or dimension in the resulting vector. The value of each feature is determined by the number of times the corresponding word appears in the text.\n",
    "\n",
    "The bag of words model is useful in NLP because it allows us to analyze text data using machine learning algorithms, which typically require numerical input. By representing text data as numerical features, we can train machine learning models to classify text or analyze sentiments.\n",
    "\n",
    "The example in the next section will use the NLTK Vader model for sentiment analysis on the Amazon customer dataset. In this particular example, we do not need to perform this step because the NLTK Vader API accepts text as an input instead of numeric vectors, but if you were building a supervised machine learning model to predict sentiment (assuming you have labeled data), you would have to transform the processed text into a bag of words model before training the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://vitalflux.com/wp-content/uploads/2021/08/Bag-of-words-technique-to-convert-to-numerical-feature-vector-png.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform sentiment analysis using NLTK in Python, the text data must first be preprocessed using techniques such as tokenization, stop word removal, and stemming or lemmatization. Once the text has been preprocessed, we will then pass it to the Vader sentiment analyzer for analyzing the sentiment of the text (positive or negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Import libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Preprocess text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a function preprocess_text in which we first tokenize the documents using word_tokenize function from NLTK, then we remove stop words using stopwords module from NLTK and finally, we lemmatize the filtered_tokens using WordNetLemmatizer from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords.words('english'):\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = []\n",
    "    for token in filtered_tokens:\n",
    "        lemmatized_token = lemmatizer.lemmatize(token)\n",
    "        lemmatized_tokens.append(lemmatized_token)\n",
    "    \n",
    "    # Join the tokens back to string\n",
    "    processed_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown each function to understand each code pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a terrific game on any pad. Hrs of fun.  My grandkids love it. Great entertainment when waiting in long lines'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_text = df[\"reviewText\"][4]\n",
    "testing_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrific',\n",
       " 'game',\n",
       " 'on',\n",
       " 'any',\n",
       " 'pad',\n",
       " '.',\n",
       " 'hrs',\n",
       " 'of',\n",
       " 'fun',\n",
       " '.',\n",
       " 'my',\n",
       " 'grandkids',\n",
       " 'love',\n",
       " 'it',\n",
       " '.',\n",
       " 'great',\n",
       " 'entertainment',\n",
       " 'when',\n",
       " 'waiting',\n",
       " 'in',\n",
       " 'long',\n",
       " 'lines']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(testing_text.lower())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = []\n",
    "for words in tokens:\n",
    "    if words not in stopwords.words('english'):\n",
    "        filtered_tokens.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terrific',\n",
       " 'game',\n",
       " 'pad',\n",
       " '.',\n",
       " 'hrs',\n",
       " 'fun',\n",
       " '.',\n",
       " 'grandkids',\n",
       " 'love',\n",
       " '.',\n",
       " 'great',\n",
       " 'entertainment',\n",
       " 'waiting',\n",
       " 'long',\n",
       " 'lines']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens = []\n",
    "\n",
    "for words in filtered_tokens:\n",
    "    lem_token = WordNetLemmatizer().lemmatize(words)\n",
    "    lemmatized_tokens.append(lem_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terrific',\n",
       " 'game',\n",
       " 'pad',\n",
       " '.',\n",
       " 'hr',\n",
       " 'fun',\n",
       " '.',\n",
       " 'grandkids',\n",
       " 'love',\n",
       " '.',\n",
       " 'great',\n",
       " 'entertainment',\n",
       " 'waiting',\n",
       " 'long',\n",
       " 'line']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This is a terrific game on any pad. Hrs of fun.  My grandkids love it. Great entertainment when waiting in long lines',\n",
       " 'terrific game pad . hr fun . grandkids love . great entertainment waiting long line')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_text, processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do for all using preprocessing funcrion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reviewText\"] = df[\"reviewText\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the df into csv file for time saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv(\"processed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free . lot different ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game . bunch level find golden egg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating , lot fun definitely re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad . hr fun . grandkids love . ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  one best apps acording bunch people agree bomb...         1\n",
       "1  pretty good version game free . lot different ...         1\n",
       "2  really cool game . bunch level find golden egg...         1\n",
       "3  silly game frustrating , lot fun definitely re...         1\n",
       "4  terrific game pad . hr fun . grandkids love . ...         1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - NLTK Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we’ll initialize a Sentiment Intensity Analyzer object from the nltk.sentiment.vader library.\n",
    "\n",
    "Next, we’ll define a function called get_sentiment that takes a text string as its input. The function calls the polarity_scores method of the analyzer object to obtain a dictionary of sentiment scores for the text, which includes a score for positive, negative, and neutral sentiment.\n",
    "\n",
    "The function will then check whether the positive score is greater than 0 and returns a sentiment score of 1 if it is, and a 0 otherwise. This means that any text with a positive score will be classified as having a positive sentiment, and any text with a non-positive score will be classified as having a negative sentiment.\n",
    "\n",
    "Finally, we’ll apply the get_sentiment function to the reviewText column of the df DataFrame using the apply method. This creates a new column called sentiment in the DataFrame, which stores the sentiment score for each review. We’ll then display the updated DataFrame using df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    if(scores['compound']>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded[\"sentiment\"] = df['reviewText'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free . lot different ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game . bunch level find golden egg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating , lot fun definitely re...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad . hr fun . grandkids love . ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>app fricken stupid.it froze kindle wont allow ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>please add ! ! ! ! ! need neighbor ! ginger101...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>love ! game . awesome . wish free stuff house ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>love love love app side fashion story fight wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>game rip . list thing make better &amp; bull ; fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  Positive  sentiment\n",
       "0      one best apps acording bunch people agree bomb...         1          1\n",
       "1      pretty good version game free . lot different ...         1          1\n",
       "2      really cool game . bunch level find golden egg...         1          1\n",
       "3      silly game frustrating , lot fun definitely re...         1          1\n",
       "4      terrific game pad . hr fun . grandkids love . ...         1          1\n",
       "...                                                  ...       ...        ...\n",
       "19995  app fricken stupid.it froze kindle wont allow ...         0          0\n",
       "19996  please add ! ! ! ! ! need neighbor ! ginger101...         1          1\n",
       "19997  love ! game . awesome . wish free stuff house ...         1          1\n",
       "19998  love love love app side fashion story fight wo...         1          1\n",
       "19999  game rip . list thing make better & bull ; fir...         0          1\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK sentiment analyzer returns a score between -1 and +1. We have used a cut-off threshold of 0 in the get_sentiment function above. Anything above 0 is classified as 1 (meaning positive). Since we have actual labels, we can evaluate the performance of this method by building a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1dd37771dd0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm =confusion_matrix(df_loaded['Positive'], df_loaded['sentiment'])\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55      4767\n",
      "           1       0.85      0.90      0.88     15233\n",
      "\n",
      "    accuracy                           0.81     20000\n",
      "   macro avg       0.74      0.70      0.72     20000\n",
      "weighted avg       0.80      0.81      0.80     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_loaded['Positive'], df_loaded['sentiment']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
